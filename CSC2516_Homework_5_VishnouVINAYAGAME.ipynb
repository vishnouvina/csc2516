{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8t21JGZyUr-"
      },
      "source": [
        "# CIFAR-10 classification \n",
        "CIFAR-10 is a standard dataset where the goal is to classify 32 x 32 images into one of 10 classes. The goal of this problem is simple: build and train a convolutional neural network to perform classification on CIFAR-10. The problem is intentionally extremely open-ended! There are dozens (hundreds?) of tutorials online describing how to train a convnet on CIFAR-10 - please seek them out and make use of them. I recommend getting started with the [CIFAR-10 tutorial from PyTorch](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb) which includes code for loading the dataset and evaluating performance on it. You are welcome to use any other resource that you want (but please cite it!) - as I mentioned there are many, many tutorials online, and googling for help is an utterly crucial skill for a researcher! You will be graded on the final test accuracy achieved by your model:\n",
        "\n",
        "- 60% accuracy or higher: 2/4 points\n",
        "- 75% accuracy or higher: 3/4 points\n",
        "- 90% accuracy or higher: 4/4 points\n",
        "- Highest accuracy in the class: 4/3 points!\n",
        "\n",
        "Note that in order for us to know the final performance of your model, you will need to implement a function that computes the accuracy of your model on the test set (which appears in both of the linked tutorials above). The only rules are: You can only train your model on the CIFAR-10 training set (i.e. you can't use pre-trained models or other datasets for additional training, and you certaintly can't train on the CIFAR-10 test set!), and you must train the model on the free Colab GPU or TPU. This means you can only train the model for an hour or so! This is *much* less compute than is typically used for training CIFAR-10 models. As such, this is as much an exercise in building an accurate model as it is in building an efficient one. This is a popular game to play, and to the best of my knowledge the state-of-the-art is [this approach](https://myrtle.ai/learn/how-to-train-your-resnet/) which attains 96% accuracy in only *26 seconds* on a single GPU! (note that the final link on that page is broken; it should be [this](https://myrtle.ai/learn/how-to-train-your-resnet-8-bag-of-tricks/))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdeYY7IVjsKq"
      },
      "source": [
        "# Explanations on my architecture\n",
        "\n",
        "I started with a very basic AlexNet, that I built using the texbook and this [tutorial](https://shonit2096.medium.com/cnn-on-cifar10-data-set-using-pytorch-34be87e09844). Using SGD and a batchsize of around 100, it gave me around 75% of accuracy on the test set, and Adam was performing slower so I decided to keep on going with SGD. I then used the textbook to add [data augmentation](https://d2l.ai/chapter_computer-vision/kaggle-cifar10.html#image-augmentation), a [learning rate scheduler](https://d2l.ai/chapter_optimization/lr-scheduler.html) (I tried LinearLR and OneCycleLR, and kept the latter).\n",
        "\n",
        "I then switched to a VGG16 architecture from this [example](https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py), but kept the architecture for the fully-connected layers of the AlexNet implementation I had because I liked the idea, and added Dropout layers to avoid overfitting, as VGG16 was overfitting by a lot in this case (which makes sense as it is a more complex network, designed for tasks like ImageNet). I managed to achieve a 85% accuracy on the test set, but was stuck there, and also had to deal with overfitting.\n",
        "\n",
        "That is when I switched to the final architecture I kept, which is a custom ResNet9. The core of the architecture comes from [tutorial](https://www.kaggle.com/code/kmldas/cifar10-resnet-90-accuracy-less-than-5-min), and it was performing to around 88-89% of accuracy on the test set with the optimizer, learning rate scheduler and other hyperparameters I chose. I also added gradient clipping just in case, following this [blog post](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem).\n",
        "Moreover, I re-implemented the AlexNet architecture for the fully-connected layers, and kept SGD for the optimizer as Adam was slower with the hyperparameters and the learning rate scheduler I chose. This made me gain around 4% of accuracy, and the final accuracy I have is around 93%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTcQJ_U3zyPq",
        "outputId": "69c476b0-4673-4dfb-f0f3-0e4b3cc61941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in ./.venv/lib/python3.9/site-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wnTamoC1IbCM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vishnouvina/Desktop/UofT/NNDL/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6DFPNkH355lV",
        "outputId": "83b6b075-86ea-4b28-c634-e66d050ba369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vArjGT8R_Sif"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_yDUHAg4_UL",
        "outputId": "d01a9e07-b61b-4cd8-dc68-f2a50d4784a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12422828.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "#We will be computing the mean and the standard deviation of the train dataset for normalization purposes\n",
        "mean_std_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mean_trainset = mean_std_set.data.mean(axis=(0,1,2))/255\n",
        "std_trainset = mean_std_set.data.std(axis=(0,1,2))/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqY419j5Ih9C",
        "outputId": "c5e472de-2094-42af-c98d-7045feeb6474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Those data augmentations are pretty arbitrary and come from the tutorials I cited\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_trainset, std_trainset)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_trainset, std_trainset)\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fZAfV8cZ37Ut"
      },
      "outputs": [],
      "source": [
        "#Custom ResNet9 architecture\n",
        "class ResNet9(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels, pool=False):\n",
        "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                    nn.ReLU(inplace=True)]\n",
        "            if pool:\n",
        "              layers.append(nn.MaxPool2d(2))\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128), nn.Dropout(p=0.3))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512), nn.Dropout(p=0.3))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Dropout(p=0.5),\n",
        "                                        nn.MaxPool2d(4),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(512, 256),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Linear(256, 128),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Dropout(p=0.5),\n",
        "                                        nn.Linear(128, num_classes)\n",
        "                                        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houDkMvG6P0x",
        "outputId": "04c098b2-ab76-4545-a6b8-f888102dca12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet9                                  [100, 10]                 --\n",
              "├─Sequential: 1-1                        [100, 64, 32, 32]         --\n",
              "│    └─Conv2d: 2-1                       [100, 64, 32, 32]         1,792\n",
              "│    └─BatchNorm2d: 2-2                  [100, 64, 32, 32]         128\n",
              "│    └─ReLU: 2-3                         [100, 64, 32, 32]         --\n",
              "├─Sequential: 1-2                        [100, 128, 16, 16]        --\n",
              "│    └─Conv2d: 2-4                       [100, 128, 32, 32]        73,856\n",
              "│    └─BatchNorm2d: 2-5                  [100, 128, 32, 32]        256\n",
              "│    └─ReLU: 2-6                         [100, 128, 32, 32]        --\n",
              "│    └─MaxPool2d: 2-7                    [100, 128, 16, 16]        --\n",
              "├─Sequential: 1-3                        [100, 128, 16, 16]        --\n",
              "│    └─Sequential: 2-8                   [100, 128, 16, 16]        --\n",
              "│    │    └─Conv2d: 3-1                  [100, 128, 16, 16]        147,584\n",
              "│    │    └─BatchNorm2d: 3-2             [100, 128, 16, 16]        256\n",
              "│    │    └─ReLU: 3-3                    [100, 128, 16, 16]        --\n",
              "│    └─Sequential: 2-9                   [100, 128, 16, 16]        --\n",
              "│    │    └─Conv2d: 3-4                  [100, 128, 16, 16]        147,584\n",
              "│    │    └─BatchNorm2d: 3-5             [100, 128, 16, 16]        256\n",
              "│    │    └─ReLU: 3-6                    [100, 128, 16, 16]        --\n",
              "│    └─Dropout: 2-10                     [100, 128, 16, 16]        --\n",
              "├─Sequential: 1-4                        [100, 256, 8, 8]          --\n",
              "│    └─Conv2d: 2-11                      [100, 256, 16, 16]        295,168\n",
              "│    └─BatchNorm2d: 2-12                 [100, 256, 16, 16]        512\n",
              "│    └─ReLU: 2-13                        [100, 256, 16, 16]        --\n",
              "│    └─MaxPool2d: 2-14                   [100, 256, 8, 8]          --\n",
              "├─Sequential: 1-5                        [100, 512, 4, 4]          --\n",
              "│    └─Conv2d: 2-15                      [100, 512, 8, 8]          1,180,160\n",
              "│    └─BatchNorm2d: 2-16                 [100, 512, 8, 8]          1,024\n",
              "│    └─ReLU: 2-17                        [100, 512, 8, 8]          --\n",
              "│    └─MaxPool2d: 2-18                   [100, 512, 4, 4]          --\n",
              "├─Sequential: 1-6                        [100, 512, 4, 4]          --\n",
              "│    └─Sequential: 2-19                  [100, 512, 4, 4]          --\n",
              "│    │    └─Conv2d: 3-7                  [100, 512, 4, 4]          2,359,808\n",
              "│    │    └─BatchNorm2d: 3-8             [100, 512, 4, 4]          1,024\n",
              "│    │    └─ReLU: 3-9                    [100, 512, 4, 4]          --\n",
              "│    └─Sequential: 2-20                  [100, 512, 4, 4]          --\n",
              "│    │    └─Conv2d: 3-10                 [100, 512, 4, 4]          2,359,808\n",
              "│    │    └─BatchNorm2d: 3-11            [100, 512, 4, 4]          1,024\n",
              "│    │    └─ReLU: 3-12                   [100, 512, 4, 4]          --\n",
              "│    └─Dropout: 2-21                     [100, 512, 4, 4]          --\n",
              "├─Sequential: 1-7                        [100, 10]                 --\n",
              "│    └─Dropout: 2-22                     [100, 512, 4, 4]          --\n",
              "│    └─MaxPool2d: 2-23                   [100, 512, 1, 1]          --\n",
              "│    └─Flatten: 2-24                     [100, 512]                --\n",
              "│    └─Linear: 2-25                      [100, 256]                131,328\n",
              "│    └─ReLU: 2-26                        [100, 256]                --\n",
              "│    └─Linear: 2-27                      [100, 128]                32,896\n",
              "│    └─ReLU: 2-28                        [100, 128]                --\n",
              "│    └─Dropout: 2-29                     [100, 128]                --\n",
              "│    └─Linear: 2-30                      [100, 10]                 1,290\n",
              "==========================================================================================\n",
              "Total params: 6,735,754\n",
              "Trainable params: 6,735,754\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 37.98\n",
              "==========================================================================================\n",
              "Input size (MB): 1.23\n",
              "Forward/backward pass size (MB): 603.25\n",
              "Params size (MB): 26.94\n",
              "Estimated Total Size (MB): 631.42\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ResNet9(3, 10).to(device)\n",
        "\n",
        "#We can vizualise the model using summary\n",
        "summary(model, input_size=(batch_size, 3, 32, 32), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "om2zn7J_-6Ne"
      },
      "outputs": [],
      "source": [
        "#Chosen hyperparameters\n",
        "\n",
        "#I first used 20-25 epochs but for the final accuracy testing, I went with 40 epochs. This takes around 25min to train on the T4 free Colab GPU\n",
        "num_epochs = 40\n",
        "\n",
        "#Initial value for the learning rate that will be fed the scheduler\n",
        "lr = 0.01\n",
        "\n",
        "#Values for momentum, weight decay and gradient clip from different cited tutorials\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "grad_clip = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ihgX8D4BbHs0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#SGD was, in my case, faster than Adam with those hyperparameters. I didn't want to look more into getting better ones for Adam\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay = weight_decay)\n",
        "\n",
        "#I tried LinearLR and OneCycleLR and the latter performed better\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(trainloader), epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKNFZ9z6tF8g",
        "outputId": "b1c0133f-92c4-404d-c3a0-e864ea33fe2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 1.59264\n",
            "Epoch 1: lr 0.00563 -> 0.00564\n",
            "Epoch: 2, Loss: 1.23602\n",
            "Epoch 2: lr 0.01042 -> 0.01043\n",
            "Epoch: 3, Loss: 1.16482\n",
            "Epoch 3: lr 0.01805 -> 0.01806\n",
            "Epoch: 4, Loss: 1.19711\n",
            "Epoch 4: lr 0.02799 -> 0.02801\n",
            "Epoch: 5, Loss: 1.23265\n",
            "Epoch 5: lr 0.03956 -> 0.03959\n",
            "Epoch: 6, Loss: 1.24349\n",
            "Epoch 6: lr 0.05199 -> 0.05201\n",
            "Epoch: 7, Loss: 1.13050\n",
            "Epoch 7: lr 0.06441 -> 0.06444\n",
            "Epoch: 8, Loss: 0.95792\n",
            "Epoch 8: lr 0.07599 -> 0.07601\n",
            "Epoch: 9, Loss: 0.87609\n",
            "Epoch 9: lr 0.08594 -> 0.08595\n",
            "Epoch: 10, Loss: 0.79271\n",
            "Epoch 10: lr 0.09357 -> 0.09358\n",
            "Epoch: 11, Loss: 0.78261\n",
            "Epoch 11: lr 0.09836 -> 0.09837\n",
            "Epoch: 12, Loss: 0.74387\n",
            "Epoch 12: lr 0.10000 -> 0.10000\n",
            "Epoch: 13, Loss: 0.70903\n",
            "Epoch 13: lr 0.09969 -> 0.09968\n",
            "Epoch: 14, Loss: 0.70037\n",
            "Epoch 14: lr 0.09875 -> 0.09874\n",
            "Epoch: 15, Loss: 0.68854\n",
            "Epoch 15: lr 0.09719 -> 0.09719\n",
            "Epoch: 16, Loss: 0.65860\n",
            "Epoch 16: lr 0.09505 -> 0.09504\n",
            "Epoch: 17, Loss: 0.63444\n",
            "Epoch 17: lr 0.09234 -> 0.09233\n",
            "Epoch: 18, Loss: 0.62074\n",
            "Epoch 18: lr 0.08909 -> 0.08908\n",
            "Epoch: 19, Loss: 0.61250\n",
            "Epoch 19: lr 0.08536 -> 0.08535\n",
            "Epoch: 20, Loss: 0.58722\n",
            "Epoch 20: lr 0.08117 -> 0.08117\n",
            "Epoch: 21, Loss: 0.58651\n",
            "Epoch 21: lr 0.07660 -> 0.07659\n",
            "Epoch: 22, Loss: 0.56487\n",
            "Epoch 22: lr 0.07169 -> 0.07168\n",
            "Epoch: 23, Loss: 0.52736\n",
            "Epoch 23: lr 0.06651 -> 0.06650\n",
            "Epoch: 24, Loss: 0.53734\n",
            "Epoch 24: lr 0.06113 -> 0.06112\n",
            "Epoch: 25, Loss: 0.51415\n",
            "Epoch 25: lr 0.05560 -> 0.05559\n",
            "Epoch: 26, Loss: 0.48676\n",
            "Epoch 26: lr 0.05000 -> 0.04999\n",
            "Epoch: 27, Loss: 0.45762\n",
            "Epoch 27: lr 0.04440 -> 0.04439\n",
            "Epoch: 28, Loss: 0.43608\n",
            "Epoch 28: lr 0.03887 -> 0.03886\n",
            "Epoch: 29, Loss: 0.40691\n",
            "Epoch 29: lr 0.03349 -> 0.03348\n",
            "Epoch: 30, Loss: 0.37937\n",
            "Epoch 30: lr 0.02831 -> 0.02830\n",
            "Epoch: 31, Loss: 0.35559\n",
            "Epoch 31: lr 0.02340 -> 0.02339\n",
            "Epoch: 32, Loss: 0.31875\n",
            "Epoch 32: lr 0.01883 -> 0.01882\n",
            "Epoch: 33, Loss: 0.28464\n",
            "Epoch 33: lr 0.01465 -> 0.01464\n",
            "Epoch: 34, Loss: 0.24447\n",
            "Epoch 34: lr 0.01091 -> 0.01090\n",
            "Epoch: 35, Loss: 0.20784\n",
            "Epoch 35: lr 0.00766 -> 0.00766\n",
            "Epoch: 36, Loss: 0.17171\n",
            "Epoch 36: lr 0.00495 -> 0.00495\n",
            "Epoch: 37, Loss: 0.13662\n",
            "Epoch 37: lr 0.00281 -> 0.00280\n",
            "Epoch: 38, Loss: 0.11340\n",
            "Epoch 38: lr 0.00125 -> 0.00125\n",
            "Epoch: 39, Loss: 0.09637\n",
            "Epoch 39: lr 0.00031 -> 0.00031\n",
            "Epoch: 40, Loss: 0.09022\n",
            "Epoch 40: lr 0.00000 -> 0.00000\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "#Loop over the dataset for as many epochs as defined\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        #Get tensors and move them to the device\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        #Backward and optimize\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        #Print the training loss at the end of each epoch\n",
        "        if not (i+1) % len(trainloader):\n",
        "            print('Epoch: %d, Loss: %.5f' %\n",
        "                  (epoch + 1, running_loss/len(trainloader)))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        before_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        scheduler.step()\n",
        "        after_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    #Print the learning rate evolution\n",
        "    print(\"Epoch %d: lr %.5f -> %.5f\" % (epoch+1, before_lr, after_lr))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1oLA1kk2rGC",
        "outputId": "589f5e64-f92f-474f-b4e2-9528c316c29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 50 000 train images: 97.24 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 50 000 train images: %.2f %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSGAw28veAid",
        "outputId": "a277c5fc-9771-414f-92b4-f55f8acfee1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10 000 test images: 92.45 %\n"
          ]
        }
      ],
      "source": [
        "#Finally, our main point of interest:\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10 000 test images: %.2f %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc8pyeyxfDDI",
        "outputId": "04c81958-ad07-43e5-9e0f-a197819e2003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 94 %\n",
            "Accuracy of   car : 97 %\n",
            "Accuracy of  bird : 89 %\n",
            "Accuracy of   cat : 83 %\n",
            "Accuracy of  deer : 94 %\n",
            "Accuracy of   dog : 88 %\n",
            "Accuracy of  frog : 94 %\n",
            "Accuracy of horse : 94 %\n",
            "Accuracy of  ship : 94 %\n",
            "Accuracy of truck : 94 %\n"
          ]
        }
      ],
      "source": [
        "#Accuracy for each class from the test set, was useful to check if the model was underperforming on some specific classes\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
