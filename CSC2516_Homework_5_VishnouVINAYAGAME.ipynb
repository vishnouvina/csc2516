{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYovBDSbwfYD"
      },
      "source": [
        "# 1. Receptive field and parameter count (1 point)\n",
        "\n",
        "Recall that the *receptive field* refers to size of the region in the input that are visible to a given activation (or neuron) in a convolutional neural network. \"Visible\" here means that the values of those inputs affect the value of the activation. In all of the following questions, assume that the input image is arbitrarily large, so you don't need to worry about boundary effects or padding.\n",
        "\n",
        "1. Consider a convolutional network which consists of three convolutional layers, each with a filter size of 3x3, and a stride of 1x1. What is the receptive field size of one of the activations at the final output?\n",
        "1. What is the receptive field if the stride is 2x3 at each layer?\n",
        "1. What is the receptive field if the stride is 2x2 at each layer, and there is a 2x2 max-pooling layer with stride 2x2 after each convolutional layer?\n",
        "1. Assume that the input image has 3 channels, the three convolutional layers have 16, 32, and 64 channels respectively, and that there are no biases on any of the layers. How many parameters does the network have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_o6Xf4A1yS"
      },
      "source": [
        "# 1. Answer\n",
        "\n",
        "1. In this question, we will be computing the receptive field regarding the x-axis, as dimensions and sizes are the same along the y-axis. Let's denote $r_l$ the number of neurons from the input of the $l$-th layer that a neuron in the final output has access to. Then, the formula to compute this value (backwards) for the layer $l-1$ is : $r_{l-1} = s_l⋅r_l + (k_l - s_l)$, where $s$ is the stride size and $k$ the kernel size. Therefore:\n",
        "*   The final output has access to 3 pixels from the input of the last convolutional layer thanks to the size of the kernel, hence $r_3 = 3$\n",
        "*   We can then compute $r_2$ : $r_2 = s_3⋅r_3 + (k_3 - s_3) = 1⋅3 + (3-1) = 5$\n",
        "*   Then, $r_1 = s_2⋅r_2 + (k_2 - s_2) = 1⋅5 + (3-1) = 7$, which means that an activation from the final output has access to 7 neurons from the input image, and therefore the receptive field is $7⋅7$\n",
        "\n",
        "\n",
        "2. We can do the same computations, but this time we have to separate accordingly for each axis:\n",
        "\n",
        "  For the x-axis:\n",
        "*   The final output has access to 3 pixels from the input of the last convolutional layer thanks to the size of the kernel, hence $r_3 = 3$\n",
        "*   Then, $r_2 = s_3⋅r_3 + (k_3 - s_3) = 2⋅3 + (3-2) = 7$\n",
        "*   Then, $r_1 = s_2⋅r_2 + (k_2 - s_2) = 2⋅7 + (3-2) = 15$\n",
        "\n",
        "  For the y-axis:\n",
        "*   The final output has access to 3 pixels from the input of the last convolutional layer thanks to the size of the kernel, hence $r_3 = 3$\n",
        "*   Then, $r_2 = s_3⋅r_3 + (k_3 - s_3) = 3⋅3 + (3-3) = 9$\n",
        "*   And, $r_1 = s_2⋅r_2 + (k_2 - s_2) = 3⋅9 + (3-3) = 27$\n",
        "\n",
        "  This means that the receptive field for an activation from the final output is $15⋅27$\n",
        "\n",
        "\n",
        "3. We do not need to be axis specific, and we can treat the max-pooling layers like we did with the convolutional layers:\n",
        "*   The final output has access to 2 pixels from the input of the last max-pooling layer thanks to its size, hence $r_6 = 2$\n",
        "*   Then for the last convolutional layer, $r_5 = s_6⋅r_6 + (k_6 - s_6) = 2⋅2 + (3-2) = 5$\n",
        "*   $r_4 = s_5⋅r_5 + (k_5 - s_5) = 2⋅5 + (3-3) = 10$\n",
        "*   $r_3 = s_4⋅r_4 + (k_4 - s_4) = 2⋅10 + (3-2) = 21$\n",
        "*   Then for the first max-pooling layer, $r_2 = s_3⋅r_3 + (k_3 - s_3) = 2⋅21 + (3-3) = 42$\n",
        "*   Finally, for the first convolutional layer, $r_1 = s_2⋅r_2 + (k_2 - s_2) = 2⋅42 + (3-2) = 85$\n",
        "\n",
        "  This means that the receptive field for an activation from the final output is $85⋅85$\n",
        "\n",
        "4. Each layer will have a number of parameters = input channels $×$ filter height $×$ filter width $×$ output_channels, as we have no bias. Therefore, the first layer will have $3×3×3×16=432$ parameters, the second one $16×3×3×32=4 608$ parameters and the third one $32×3×3×64=18 432$. The total number of parameters is the sum of those 3 numbers, which is $23 472$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8t21JGZyUr-"
      },
      "source": [
        "# 2. CIFAR-10 classification (4 points)\n",
        "\n",
        "CIFAR-10 is a standard dataset where the goal is to classify 32 x 32 images into one of 10 classes. The goal of this problem is simple: build and train a convolutional neural network to perform classification on CIFAR-10. The problem is intentionally extremely open-ended! There are dozens (hundreds?) of tutorials online describing how to train a convnet on CIFAR-10 - please seek them out and make use of them. I recommend getting started with the [CIFAR-10 tutorial from PyTorch](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb) which includes code for loading the dataset and evaluating performance on it. You are welcome to use any other resource that you want (but please cite it!) - as I mentioned there are many, many tutorials online, and googling for help is an utterly crucial skill for a researcher! You will be graded on the final test accuracy achieved by your model:\n",
        "\n",
        "- 60% accuracy or higher: 2/4 points\n",
        "- 75% accuracy or higher: 3/4 points\n",
        "- 90% accuracy or higher: 4/4 points\n",
        "- Highest accuracy in the class: 4/3 points!\n",
        "\n",
        "Note that in order for us to know the final performance of your model, you will need to implement a function that computes the accuracy of your model on the test set (which appears in both of the linked tutorials above). The only rules are: You can only train your model on the CIFAR-10 training set (i.e. you can't use pre-trained models or other datasets for additional training, and you certaintly can't train on the CIFAR-10 test set!), and you must train the model on the free Colab GPU or TPU. This means you can only train the model for an hour or so! This is *much* less compute than is typically used for training CIFAR-10 models. As such, this is as much an exercise in building an accurate model as it is in building an efficient one. This is a popular game to play, and to the best of my knowledge the state-of-the-art is [this approach](https://myrtle.ai/learn/how-to-train-your-resnet/) which attains 96% accuracy in only *26 seconds* on a single GPU! (note that the final link on that page is broken; it should be [this](https://myrtle.ai/learn/how-to-train-your-resnet-8-bag-of-tricks/)).\n",
        "\n",
        "There are lots of things you can try to make your model more accurate and/or more efficient:\n",
        "\n",
        "1. Deeper models\n",
        "1. Residual connections\n",
        "1. [Data augmentation and normalization](https://d2l.ai/chapter_computer-vision/kaggle-cifar10.html#image-augmentation)\n",
        "1. Regularization like dropout or weight decay\n",
        "1. [Learning rate schedules](https://d2l.ai/chapter_optimization/lr-scheduler.html)\n",
        "1. [Different forms of normalization](https://d2l.ai/chapter_convolutional-modern/batch-norm.html)\n",
        "\n",
        "Note that we haven't covered all these topics in class yet, but you should be able to get to at least 60% accuracy without applying all of these ideas - and probably 75% by tweaking around a little bit. Specifically, you should be able to get about 60% accuracy by taking the basic AlexNet architecture we discussed in class and applying it directly to CIFAR-10. And, if you're feeling adventurous, feel free to go for 96% using the aforementioned blog series! Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdeYY7IVjsKq"
      },
      "source": [
        "# 2. Explanations on my architecture\n",
        "\n",
        "I started with a very basic AlexNet, that I built using the texbook and this [tutorial](https://shonit2096.medium.com/cnn-on-cifar10-data-set-using-pytorch-34be87e09844). Using SGD and a batchsize of around 100, it gave me around 75% of accuracy on the test set, and Adam was performing slower so I decided to keep on going with SGD. I then used the textbook to add [data augmentation](https://d2l.ai/chapter_computer-vision/kaggle-cifar10.html#image-augmentation), a [learning rate scheduler](https://d2l.ai/chapter_optimization/lr-scheduler.html) (I tried LinearLR and OneCycleLR, and kept the latter).\n",
        "\n",
        "I then switched to a VGG16 architecture from this [example](https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py), but kept the architecture for the fully-connected layers of the AlexNet implementation I had because I liked the idea, and added Dropout layers to avoid overfitting, as VGG16 was overfitting by a lot in this case (which makes sense as it is a more complex network, designed for tasks like ImageNet). I managed to achieve a 85% accuracy on the test set, but was stuck there, and also had to deal with overfitting.\n",
        "\n",
        "That is when I switched to the final architecture I kept, which is a custom ResNet9. The core of the architecture comes from [tutorial](https://www.kaggle.com/code/kmldas/cifar10-resnet-90-accuracy-less-than-5-min), and it was performing to around 88-89% of accuracy on the test set with the optimizer, learning rate scheduler and other hyperparameters I chose. I also added gradient clipping just in case, following this [blog post](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem).\n",
        "Moreover, I re-implemented the AlexNet architecture for the fully-connected layers, and kept SGD for the optimizer as Adam was slower with the hyperparameters and the learning rate scheduler I chose. This made me gain around 4% of accuracy, and the final accuracy I have is around 93%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTcQJ_U3zyPq",
        "outputId": "69c476b0-4673-4dfb-f0f3-0e4b3cc61941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in ./.venv/lib/python3.9/site-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wnTamoC1IbCM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vishnouvina/Desktop/UofT/NNDL/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6DFPNkH355lV",
        "outputId": "83b6b075-86ea-4b28-c634-e66d050ba369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vArjGT8R_Sif"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_yDUHAg4_UL",
        "outputId": "d01a9e07-b61b-4cd8-dc68-f2a50d4784a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12422828.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "#We will be computing the mean and the standard deviation of the train dataset for normalization purposes\n",
        "mean_std_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "mean_trainset = mean_std_set.data.mean(axis=(0,1,2))/255\n",
        "std_trainset = mean_std_set.data.std(axis=(0,1,2))/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqY419j5Ih9C",
        "outputId": "c5e472de-2094-42af-c98d-7045feeb6474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Those data augmentations are pretty arbitrary and come from the tutorials I cited\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_trainset, std_trainset)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_trainset, std_trainset)\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fZAfV8cZ37Ut"
      },
      "outputs": [],
      "source": [
        "#Custom ResNet9 architecture\n",
        "class ResNet9(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels, pool=False):\n",
        "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                    nn.ReLU(inplace=True)]\n",
        "            if pool:\n",
        "              layers.append(nn.MaxPool2d(2))\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128), nn.Dropout(p=0.3))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512), nn.Dropout(p=0.3))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Dropout(p=0.5),\n",
        "                                        nn.MaxPool2d(4),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(512, 256),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Linear(256, 128),\n",
        "                                        nn.ReLU(inplace=True),\n",
        "                                        nn.Dropout(p=0.5),\n",
        "                                        nn.Linear(128, num_classes)\n",
        "                                        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houDkMvG6P0x",
        "outputId": "04c098b2-ab76-4545-a6b8-f888102dca12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet9                                  [100, 10]                 --\n",
              "├─Sequential: 1-1                        [100, 64, 32, 32]         --\n",
              "│    └─Conv2d: 2-1                       [100, 64, 32, 32]         1,792\n",
              "│    └─BatchNorm2d: 2-2                  [100, 64, 32, 32]         128\n",
              "│    └─ReLU: 2-3                         [100, 64, 32, 32]         --\n",
              "├─Sequential: 1-2                        [100, 128, 16, 16]        --\n",
              "│    └─Conv2d: 2-4                       [100, 128, 32, 32]        73,856\n",
              "│    └─BatchNorm2d: 2-5                  [100, 128, 32, 32]        256\n",
              "│    └─ReLU: 2-6                         [100, 128, 32, 32]        --\n",
              "│    └─MaxPool2d: 2-7                    [100, 128, 16, 16]        --\n",
              "├─Sequential: 1-3                        [100, 128, 16, 16]        --\n",
              "│    └─Sequential: 2-8                   [100, 128, 16, 16]        --\n",
              "│    │    └─Conv2d: 3-1                  [100, 128, 16, 16]        147,584\n",
              "│    │    └─BatchNorm2d: 3-2             [100, 128, 16, 16]        256\n",
              "│    │    └─ReLU: 3-3                    [100, 128, 16, 16]        --\n",
              "│    └─Sequential: 2-9                   [100, 128, 16, 16]        --\n",
              "│    │    └─Conv2d: 3-4                  [100, 128, 16, 16]        147,584\n",
              "│    │    └─BatchNorm2d: 3-5             [100, 128, 16, 16]        256\n",
              "│    │    └─ReLU: 3-6                    [100, 128, 16, 16]        --\n",
              "│    └─Dropout: 2-10                     [100, 128, 16, 16]        --\n",
              "├─Sequential: 1-4                        [100, 256, 8, 8]          --\n",
              "│    └─Conv2d: 2-11                      [100, 256, 16, 16]        295,168\n",
              "│    └─BatchNorm2d: 2-12                 [100, 256, 16, 16]        512\n",
              "│    └─ReLU: 2-13                        [100, 256, 16, 16]        --\n",
              "│    └─MaxPool2d: 2-14                   [100, 256, 8, 8]          --\n",
              "├─Sequential: 1-5                        [100, 512, 4, 4]          --\n",
              "│    └─Conv2d: 2-15                      [100, 512, 8, 8]          1,180,160\n",
              "│    └─BatchNorm2d: 2-16                 [100, 512, 8, 8]          1,024\n",
              "│    └─ReLU: 2-17                        [100, 512, 8, 8]          --\n",
              "│    └─MaxPool2d: 2-18                   [100, 512, 4, 4]          --\n",
              "├─Sequential: 1-6                        [100, 512, 4, 4]          --\n",
              "│    └─Sequential: 2-19                  [100, 512, 4, 4]          --\n",
              "│    │    └─Conv2d: 3-7                  [100, 512, 4, 4]          2,359,808\n",
              "│    │    └─BatchNorm2d: 3-8             [100, 512, 4, 4]          1,024\n",
              "│    │    └─ReLU: 3-9                    [100, 512, 4, 4]          --\n",
              "│    └─Sequential: 2-20                  [100, 512, 4, 4]          --\n",
              "│    │    └─Conv2d: 3-10                 [100, 512, 4, 4]          2,359,808\n",
              "│    │    └─BatchNorm2d: 3-11            [100, 512, 4, 4]          1,024\n",
              "│    │    └─ReLU: 3-12                   [100, 512, 4, 4]          --\n",
              "│    └─Dropout: 2-21                     [100, 512, 4, 4]          --\n",
              "├─Sequential: 1-7                        [100, 10]                 --\n",
              "│    └─Dropout: 2-22                     [100, 512, 4, 4]          --\n",
              "│    └─MaxPool2d: 2-23                   [100, 512, 1, 1]          --\n",
              "│    └─Flatten: 2-24                     [100, 512]                --\n",
              "│    └─Linear: 2-25                      [100, 256]                131,328\n",
              "│    └─ReLU: 2-26                        [100, 256]                --\n",
              "│    └─Linear: 2-27                      [100, 128]                32,896\n",
              "│    └─ReLU: 2-28                        [100, 128]                --\n",
              "│    └─Dropout: 2-29                     [100, 128]                --\n",
              "│    └─Linear: 2-30                      [100, 10]                 1,290\n",
              "==========================================================================================\n",
              "Total params: 6,735,754\n",
              "Trainable params: 6,735,754\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 37.98\n",
              "==========================================================================================\n",
              "Input size (MB): 1.23\n",
              "Forward/backward pass size (MB): 603.25\n",
              "Params size (MB): 26.94\n",
              "Estimated Total Size (MB): 631.42\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ResNet9(3, 10).to(device)\n",
        "\n",
        "#We can vizualise the model using summary\n",
        "summary(model, input_size=(batch_size, 3, 32, 32), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "om2zn7J_-6Ne"
      },
      "outputs": [],
      "source": [
        "#Chosen hyperparameters\n",
        "\n",
        "#I first used 20-25 epochs but for the final accuracy testing, I went with 40 epochs. This takes around 25min to train on the T4 free Colab GPU\n",
        "num_epochs = 40\n",
        "\n",
        "#Initial value for the learning rate that will be fed the scheduler\n",
        "lr = 0.01\n",
        "\n",
        "#Values for momentum, weight decay and gradient clip from different cited tutorials\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "grad_clip = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ihgX8D4BbHs0"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#SGD was, in my case, faster than Adam with those hyperparameters. I didn't want to look more into getting better ones for Adam\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay = weight_decay)\n",
        "\n",
        "#I tried LinearLR and OneCycleLR and the latter performed better\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(trainloader), epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKNFZ9z6tF8g",
        "outputId": "b1c0133f-92c4-404d-c3a0-e864ea33fe2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 1.59264\n",
            "Epoch 1: lr 0.00563 -> 0.00564\n",
            "Epoch: 2, Loss: 1.23602\n",
            "Epoch 2: lr 0.01042 -> 0.01043\n",
            "Epoch: 3, Loss: 1.16482\n",
            "Epoch 3: lr 0.01805 -> 0.01806\n",
            "Epoch: 4, Loss: 1.19711\n",
            "Epoch 4: lr 0.02799 -> 0.02801\n",
            "Epoch: 5, Loss: 1.23265\n",
            "Epoch 5: lr 0.03956 -> 0.03959\n",
            "Epoch: 6, Loss: 1.24349\n",
            "Epoch 6: lr 0.05199 -> 0.05201\n",
            "Epoch: 7, Loss: 1.13050\n",
            "Epoch 7: lr 0.06441 -> 0.06444\n",
            "Epoch: 8, Loss: 0.95792\n",
            "Epoch 8: lr 0.07599 -> 0.07601\n",
            "Epoch: 9, Loss: 0.87609\n",
            "Epoch 9: lr 0.08594 -> 0.08595\n",
            "Epoch: 10, Loss: 0.79271\n",
            "Epoch 10: lr 0.09357 -> 0.09358\n",
            "Epoch: 11, Loss: 0.78261\n",
            "Epoch 11: lr 0.09836 -> 0.09837\n",
            "Epoch: 12, Loss: 0.74387\n",
            "Epoch 12: lr 0.10000 -> 0.10000\n",
            "Epoch: 13, Loss: 0.70903\n",
            "Epoch 13: lr 0.09969 -> 0.09968\n",
            "Epoch: 14, Loss: 0.70037\n",
            "Epoch 14: lr 0.09875 -> 0.09874\n",
            "Epoch: 15, Loss: 0.68854\n",
            "Epoch 15: lr 0.09719 -> 0.09719\n",
            "Epoch: 16, Loss: 0.65860\n",
            "Epoch 16: lr 0.09505 -> 0.09504\n",
            "Epoch: 17, Loss: 0.63444\n",
            "Epoch 17: lr 0.09234 -> 0.09233\n",
            "Epoch: 18, Loss: 0.62074\n",
            "Epoch 18: lr 0.08909 -> 0.08908\n",
            "Epoch: 19, Loss: 0.61250\n",
            "Epoch 19: lr 0.08536 -> 0.08535\n",
            "Epoch: 20, Loss: 0.58722\n",
            "Epoch 20: lr 0.08117 -> 0.08117\n",
            "Epoch: 21, Loss: 0.58651\n",
            "Epoch 21: lr 0.07660 -> 0.07659\n",
            "Epoch: 22, Loss: 0.56487\n",
            "Epoch 22: lr 0.07169 -> 0.07168\n",
            "Epoch: 23, Loss: 0.52736\n",
            "Epoch 23: lr 0.06651 -> 0.06650\n",
            "Epoch: 24, Loss: 0.53734\n",
            "Epoch 24: lr 0.06113 -> 0.06112\n",
            "Epoch: 25, Loss: 0.51415\n",
            "Epoch 25: lr 0.05560 -> 0.05559\n",
            "Epoch: 26, Loss: 0.48676\n",
            "Epoch 26: lr 0.05000 -> 0.04999\n",
            "Epoch: 27, Loss: 0.45762\n",
            "Epoch 27: lr 0.04440 -> 0.04439\n",
            "Epoch: 28, Loss: 0.43608\n",
            "Epoch 28: lr 0.03887 -> 0.03886\n",
            "Epoch: 29, Loss: 0.40691\n",
            "Epoch 29: lr 0.03349 -> 0.03348\n",
            "Epoch: 30, Loss: 0.37937\n",
            "Epoch 30: lr 0.02831 -> 0.02830\n",
            "Epoch: 31, Loss: 0.35559\n",
            "Epoch 31: lr 0.02340 -> 0.02339\n",
            "Epoch: 32, Loss: 0.31875\n",
            "Epoch 32: lr 0.01883 -> 0.01882\n",
            "Epoch: 33, Loss: 0.28464\n",
            "Epoch 33: lr 0.01465 -> 0.01464\n",
            "Epoch: 34, Loss: 0.24447\n",
            "Epoch 34: lr 0.01091 -> 0.01090\n",
            "Epoch: 35, Loss: 0.20784\n",
            "Epoch 35: lr 0.00766 -> 0.00766\n",
            "Epoch: 36, Loss: 0.17171\n",
            "Epoch 36: lr 0.00495 -> 0.00495\n",
            "Epoch: 37, Loss: 0.13662\n",
            "Epoch 37: lr 0.00281 -> 0.00280\n",
            "Epoch: 38, Loss: 0.11340\n",
            "Epoch 38: lr 0.00125 -> 0.00125\n",
            "Epoch: 39, Loss: 0.09637\n",
            "Epoch 39: lr 0.00031 -> 0.00031\n",
            "Epoch: 40, Loss: 0.09022\n",
            "Epoch 40: lr 0.00000 -> 0.00000\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "#Loop over the dataset for as many epochs as defined\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        #Get tensors and move them to the device\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        #Backward and optimize\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        #Print the training loss at the end of each epoch\n",
        "        if not (i+1) % len(trainloader):\n",
        "            print('Epoch: %d, Loss: %.5f' %\n",
        "                  (epoch + 1, running_loss/len(trainloader)))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        before_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        scheduler.step()\n",
        "        after_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    #Print the learning rate evolution\n",
        "    print(\"Epoch %d: lr %.5f -> %.5f\" % (epoch+1, before_lr, after_lr))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1oLA1kk2rGC",
        "outputId": "589f5e64-f92f-474f-b4e2-9528c316c29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 50 000 train images: 97.24 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 50 000 train images: %.2f %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSGAw28veAid",
        "outputId": "a277c5fc-9771-414f-92b4-f55f8acfee1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10 000 test images: 92.45 %\n"
          ]
        }
      ],
      "source": [
        "#Finally, our main point of interest:\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10 000 test images: %.2f %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc8pyeyxfDDI",
        "outputId": "04c81958-ad07-43e5-9e0f-a197819e2003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 94 %\n",
            "Accuracy of   car : 97 %\n",
            "Accuracy of  bird : 89 %\n",
            "Accuracy of   cat : 83 %\n",
            "Accuracy of  deer : 94 %\n",
            "Accuracy of   dog : 88 %\n",
            "Accuracy of  frog : 94 %\n",
            "Accuracy of horse : 94 %\n",
            "Accuracy of  ship : 94 %\n",
            "Accuracy of truck : 94 %\n"
          ]
        }
      ],
      "source": [
        "#Accuracy for each class from the test set, was useful to check if the model was underperforming on some specific classes\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CustomCNN                                [100, 10]                 --\n",
              "├─Sequential: 1-1                        [32, 16, 16]              --\n",
              "│    └─Conv2d: 2-1                       [32, 32, 32]              2,432\n",
              "│    └─ReLU: 2-2                         [32, 32, 32]              --\n",
              "│    └─MaxPool2d: 2-3                    [32, 16, 16]              --\n",
              "├─Sequential: 1-2                        [64, 8, 8]                --\n",
              "│    └─Conv2d: 2-4                       [64, 16, 16]              18,496\n",
              "│    └─ReLU: 2-5                         [64, 16, 16]              --\n",
              "│    └─MaxPool2d: 2-6                    [64, 8, 8]                --\n",
              "├─Sequential: 1-3                        [100, 8, 8]               --\n",
              "│    └─Conv2d: 2-7                       [100, 8, 8]               6,500\n",
              "├─Sequential: 1-4                        [100, 10]                 --\n",
              "│    └─Flatten: 2-8                      [100, 64]                 --\n",
              "│    └─Linear: 2-9                       [100, 10]                 650\n",
              "│    └─Softmax: 2-10                     [100, 10]                 --\n",
              "==========================================================================================\n",
              "Total params: 28,078\n",
              "Trainable params: 28,078\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 26.70\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.45\n",
              "Params size (MB): 0.11\n",
              "Estimated Total Size (MB): 0.58\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        \n",
        "        # First convolutional block\n",
        "        self.block1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
        "                                    nn.ReLU(),\n",
        "                                    #nn.BatchNorm2d(num_features=32),\n",
        "                                    nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "        \n",
        "    # Second convolutional block\n",
        "        self.block2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.ReLU(),\n",
        "                            #nn.BatchNorm2d(num_features=64),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "        \n",
        "        # Third convolutional block\n",
        "        self.block3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=100, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(nn.Flatten(),\n",
        "                                        nn.Linear(8*8, 10),\n",
        "                                        nn.Softmax(),\n",
        "                                        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First block\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = CustomCNN()\n",
        "model.eval()\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#array with values between -1000 and 1000 evenly spaced\n",
        "g = np.linspace(-0.5, 0.5, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = g/(np.abs(g) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x166865c70>]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(g,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
